||||||||||| Model Stru |||||||||||
module.patch_embed.proj.weight
module.layers.0.blocks.0.attn.qkv.weight
module.layers.0.blocks.0.attn.proj.weight
module.layers.0.blocks.0.mlp.fc1.weight
module.layers.0.blocks.0.mlp.fc2.weight
module.layers.0.blocks.1.attn.qkv.weight
module.layers.0.blocks.1.attn.proj.weight
module.layers.0.blocks.1.mlp.fc1.weight
module.layers.0.blocks.1.mlp.fc2.weight
module.layers.0.downsample.reduction.weight
module.layers.1.blocks.0.attn.qkv.weight
module.layers.1.blocks.0.attn.proj.weight
module.layers.1.blocks.0.mlp.fc1.weight
module.layers.1.blocks.0.mlp.fc2.weight
module.layers.1.blocks.1.attn.qkv.weight
module.layers.1.blocks.1.attn.proj.weight
module.layers.1.blocks.1.mlp.fc1.weight
module.layers.1.blocks.1.mlp.fc2.weight
module.layers.1.downsample.reduction.weight
module.layers.2.blocks.0.attn.qkv.weight
module.layers.2.blocks.0.attn.proj.weight
module.layers.2.blocks.0.mlp.fc1.weight
module.layers.2.blocks.0.mlp.fc2.weight
module.layers.2.blocks.1.attn.qkv.weight
module.layers.2.blocks.1.attn.proj.weight
module.layers.2.blocks.1.mlp.fc1.weight
module.layers.2.blocks.1.mlp.fc2.weight
module.layers.2.blocks.2.attn.qkv.weight
module.layers.2.blocks.2.attn.proj.weight
module.layers.2.blocks.2.mlp.fc1.weight
module.layers.2.blocks.2.mlp.fc2.weight
module.layers.2.blocks.3.attn.qkv.weight
module.layers.2.blocks.3.attn.proj.weight
module.layers.2.blocks.3.mlp.fc1.weight
module.layers.2.blocks.3.mlp.fc2.weight
module.layers.2.blocks.4.attn.qkv.weight
module.layers.2.blocks.4.attn.proj.weight
module.layers.2.blocks.4.mlp.fc1.weight
module.layers.2.blocks.4.mlp.fc2.weight
module.layers.2.blocks.5.attn.qkv.weight
module.layers.2.blocks.5.attn.proj.weight
module.layers.2.blocks.5.mlp.fc1.weight
module.layers.2.blocks.5.mlp.fc2.weight
module.layers.2.downsample.reduction.weight
module.layers.3.blocks.0.attn.qkv.weight
module.layers.3.blocks.0.attn.proj.weight
module.layers.3.blocks.0.mlp.fc1.weight
module.layers.3.blocks.0.mlp.fc2.weight
module.layers.3.blocks.1.attn.qkv.weight
module.layers.3.blocks.1.attn.proj.weight
module.layers.3.blocks.1.mlp.fc1.weight
module.layers.3.blocks.1.mlp.fc2.weight
module.head.weight
0 th weight: module.patch_embed.proj.weight , shape =  torch.Size([96, 3, 4, 4]) , weight.dtype =  torch.float32
1 th weight: module.patch_embed.proj.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
2 th weight: module.patch_embed.norm.weight , shape =  torch.Size([96]) , weight.dtype =  torch.float32
3 th weight: module.patch_embed.norm.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
4 th weight: module.layers.0.blocks.0.norm1.weight , shape =  torch.Size([96]) , weight.dtype =  torch.float32
5 th weight: module.layers.0.blocks.0.norm1.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
6 th weight: module.layers.0.blocks.0.attn.relative_position_bias_table , shape =  torch.Size([169, 3]) , weight.dtype =  torch.float32
7 th weight: module.layers.0.blocks.0.attn.qkv.weight , shape =  torch.Size([288, 96]) , weight.dtype =  torch.float32
8 th weight: module.layers.0.blocks.0.attn.qkv.bias , shape =  torch.Size([288]) , weight.dtype =  torch.float32
9 th weight: module.layers.0.blocks.0.attn.proj.weight , shape =  torch.Size([96, 96]) , weight.dtype =  torch.float32
10 th weight: module.layers.0.blocks.0.attn.proj.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
11 th weight: module.layers.0.blocks.0.norm2.weight , shape =  torch.Size([96]) , weight.dtype =  torch.float32
12 th weight: module.layers.0.blocks.0.norm2.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
13 th weight: module.layers.0.blocks.0.mlp.fc1.weight , shape =  torch.Size([384, 96]) , weight.dtype =  torch.float32
14 th weight: module.layers.0.blocks.0.mlp.fc1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
15 th weight: module.layers.0.blocks.0.mlp.fc2.weight , shape =  torch.Size([96, 384]) , weight.dtype =  torch.float32
16 th weight: module.layers.0.blocks.0.mlp.fc2.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
17 th weight: module.layers.0.blocks.1.norm1.weight , shape =  torch.Size([96]) , weight.dtype =  torch.float32
18 th weight: module.layers.0.blocks.1.norm1.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
19 th weight: module.layers.0.blocks.1.attn.relative_position_bias_table , shape =  torch.Size([169, 3]) , weight.dtype =  torch.float32
20 th weight: module.layers.0.blocks.1.attn.qkv.weight , shape =  torch.Size([288, 96]) , weight.dtype =  torch.float32
21 th weight: module.layers.0.blocks.1.attn.qkv.bias , shape =  torch.Size([288]) , weight.dtype =  torch.float32
22 th weight: module.layers.0.blocks.1.attn.proj.weight , shape =  torch.Size([96, 96]) , weight.dtype =  torch.float32
23 th weight: module.layers.0.blocks.1.attn.proj.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
24 th weight: module.layers.0.blocks.1.norm2.weight , shape =  torch.Size([96]) , weight.dtype =  torch.float32
25 th weight: module.layers.0.blocks.1.norm2.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
26 th weight: module.layers.0.blocks.1.mlp.fc1.weight , shape =  torch.Size([384, 96]) , weight.dtype =  torch.float32
27 th weight: module.layers.0.blocks.1.mlp.fc1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
28 th weight: module.layers.0.blocks.1.mlp.fc2.weight , shape =  torch.Size([96, 384]) , weight.dtype =  torch.float32
29 th weight: module.layers.0.blocks.1.mlp.fc2.bias , shape =  torch.Size([96]) , weight.dtype =  torch.float32
30 th weight: module.layers.0.downsample.reduction.weight , shape =  torch.Size([192, 384]) , weight.dtype =  torch.float32
31 th weight: module.layers.0.downsample.norm.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
32 th weight: module.layers.0.downsample.norm.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
33 th weight: module.layers.1.blocks.0.norm1.weight , shape =  torch.Size([192]) , weight.dtype =  torch.float32
34 th weight: module.layers.1.blocks.0.norm1.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
35 th weight: module.layers.1.blocks.0.attn.relative_position_bias_table , shape =  torch.Size([169, 6]) , weight.dtype =  torch.float32
36 th weight: module.layers.1.blocks.0.attn.qkv.weight , shape =  torch.Size([576, 192]) , weight.dtype =  torch.float32
37 th weight: module.layers.1.blocks.0.attn.qkv.bias , shape =  torch.Size([576]) , weight.dtype =  torch.float32
38 th weight: module.layers.1.blocks.0.attn.proj.weight , shape =  torch.Size([192, 192]) , weight.dtype =  torch.float32
39 th weight: module.layers.1.blocks.0.attn.proj.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
40 th weight: module.layers.1.blocks.0.norm2.weight , shape =  torch.Size([192]) , weight.dtype =  torch.float32
41 th weight: module.layers.1.blocks.0.norm2.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
42 th weight: module.layers.1.blocks.0.mlp.fc1.weight , shape =  torch.Size([768, 192]) , weight.dtype =  torch.float32
43 th weight: module.layers.1.blocks.0.mlp.fc1.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
44 th weight: module.layers.1.blocks.0.mlp.fc2.weight , shape =  torch.Size([192, 768]) , weight.dtype =  torch.float32
45 th weight: module.layers.1.blocks.0.mlp.fc2.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
46 th weight: module.layers.1.blocks.1.norm1.weight , shape =  torch.Size([192]) , weight.dtype =  torch.float32
47 th weight: module.layers.1.blocks.1.norm1.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
48 th weight: module.layers.1.blocks.1.attn.relative_position_bias_table , shape =  torch.Size([169, 6]) , weight.dtype =  torch.float32
49 th weight: module.layers.1.blocks.1.attn.qkv.weight , shape =  torch.Size([576, 192]) , weight.dtype =  torch.float32
50 th weight: module.layers.1.blocks.1.attn.qkv.bias , shape =  torch.Size([576]) , weight.dtype =  torch.float32
51 th weight: module.layers.1.blocks.1.attn.proj.weight , shape =  torch.Size([192, 192]) , weight.dtype =  torch.float32
52 th weight: module.layers.1.blocks.1.attn.proj.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
53 th weight: module.layers.1.blocks.1.norm2.weight , shape =  torch.Size([192]) , weight.dtype =  torch.float32
54 th weight: module.layers.1.blocks.1.norm2.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
55 th weight: module.layers.1.blocks.1.mlp.fc1.weight , shape =  torch.Size([768, 192]) , weight.dtype =  torch.float32
56 th weight: module.layers.1.blocks.1.mlp.fc1.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
57 th weight: module.layers.1.blocks.1.mlp.fc2.weight , shape =  torch.Size([192, 768]) , weight.dtype =  torch.float32
58 th weight: module.layers.1.blocks.1.mlp.fc2.bias , shape =  torch.Size([192]) , weight.dtype =  torch.float32
59 th weight: module.layers.1.downsample.reduction.weight , shape =  torch.Size([384, 768]) , weight.dtype =  torch.float32
60 th weight: module.layers.1.downsample.norm.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
61 th weight: module.layers.1.downsample.norm.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
62 th weight: module.layers.2.blocks.0.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
63 th weight: module.layers.2.blocks.0.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
64 th weight: module.layers.2.blocks.0.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
65 th weight: module.layers.2.blocks.0.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
66 th weight: module.layers.2.blocks.0.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
67 th weight: module.layers.2.blocks.0.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
68 th weight: module.layers.2.blocks.0.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
69 th weight: module.layers.2.blocks.0.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
70 th weight: module.layers.2.blocks.0.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
71 th weight: module.layers.2.blocks.0.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
72 th weight: module.layers.2.blocks.0.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
73 th weight: module.layers.2.blocks.0.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
74 th weight: module.layers.2.blocks.0.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
75 th weight: module.layers.2.blocks.1.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
76 th weight: module.layers.2.blocks.1.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
77 th weight: module.layers.2.blocks.1.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
78 th weight: module.layers.2.blocks.1.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
79 th weight: module.layers.2.blocks.1.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
80 th weight: module.layers.2.blocks.1.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
81 th weight: module.layers.2.blocks.1.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
82 th weight: module.layers.2.blocks.1.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
83 th weight: module.layers.2.blocks.1.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
84 th weight: module.layers.2.blocks.1.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
85 th weight: module.layers.2.blocks.1.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
86 th weight: module.layers.2.blocks.1.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
87 th weight: module.layers.2.blocks.1.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
88 th weight: module.layers.2.blocks.2.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
89 th weight: module.layers.2.blocks.2.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
90 th weight: module.layers.2.blocks.2.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
91 th weight: module.layers.2.blocks.2.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
92 th weight: module.layers.2.blocks.2.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
93 th weight: module.layers.2.blocks.2.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
94 th weight: module.layers.2.blocks.2.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
95 th weight: module.layers.2.blocks.2.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
96 th weight: module.layers.2.blocks.2.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
97 th weight: module.layers.2.blocks.2.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
98 th weight: module.layers.2.blocks.2.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
99 th weight: module.layers.2.blocks.2.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
100 th weight: module.layers.2.blocks.2.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
101 th weight: module.layers.2.blocks.3.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
102 th weight: module.layers.2.blocks.3.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
103 th weight: module.layers.2.blocks.3.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
104 th weight: module.layers.2.blocks.3.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
105 th weight: module.layers.2.blocks.3.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
106 th weight: module.layers.2.blocks.3.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
107 th weight: module.layers.2.blocks.3.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
108 th weight: module.layers.2.blocks.3.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
109 th weight: module.layers.2.blocks.3.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
110 th weight: module.layers.2.blocks.3.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
111 th weight: module.layers.2.blocks.3.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
112 th weight: module.layers.2.blocks.3.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
113 th weight: module.layers.2.blocks.3.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
114 th weight: module.layers.2.blocks.4.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
115 th weight: module.layers.2.blocks.4.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
116 th weight: module.layers.2.blocks.4.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
117 th weight: module.layers.2.blocks.4.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
118 th weight: module.layers.2.blocks.4.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
119 th weight: module.layers.2.blocks.4.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
120 th weight: module.layers.2.blocks.4.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
121 th weight: module.layers.2.blocks.4.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
122 th weight: module.layers.2.blocks.4.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
123 th weight: module.layers.2.blocks.4.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
124 th weight: module.layers.2.blocks.4.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
125 th weight: module.layers.2.blocks.4.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
126 th weight: module.layers.2.blocks.4.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
127 th weight: module.layers.2.blocks.5.norm1.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
128 th weight: module.layers.2.blocks.5.norm1.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
129 th weight: module.layers.2.blocks.5.attn.relative_position_bias_table , shape =  torch.Size([169, 12]) , weight.dtype =  torch.float32
130 th weight: module.layers.2.blocks.5.attn.qkv.weight , shape =  torch.Size([1152, 384]) , weight.dtype =  torch.float32
131 th weight: module.layers.2.blocks.5.attn.qkv.bias , shape =  torch.Size([1152]) , weight.dtype =  torch.float32
132 th weight: module.layers.2.blocks.5.attn.proj.weight , shape =  torch.Size([384, 384]) , weight.dtype =  torch.float32
133 th weight: module.layers.2.blocks.5.attn.proj.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
134 th weight: module.layers.2.blocks.5.norm2.weight , shape =  torch.Size([384]) , weight.dtype =  torch.float32
135 th weight: module.layers.2.blocks.5.norm2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
136 th weight: module.layers.2.blocks.5.mlp.fc1.weight , shape =  torch.Size([1536, 384]) , weight.dtype =  torch.float32
137 th weight: module.layers.2.blocks.5.mlp.fc1.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
138 th weight: module.layers.2.blocks.5.mlp.fc2.weight , shape =  torch.Size([384, 1536]) , weight.dtype =  torch.float32
139 th weight: module.layers.2.blocks.5.mlp.fc2.bias , shape =  torch.Size([384]) , weight.dtype =  torch.float32
140 th weight: module.layers.2.downsample.reduction.weight , shape =  torch.Size([768, 1536]) , weight.dtype =  torch.float32
141 th weight: module.layers.2.downsample.norm.weight , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
142 th weight: module.layers.2.downsample.norm.bias , shape =  torch.Size([1536]) , weight.dtype =  torch.float32
143 th weight: module.layers.3.blocks.0.norm1.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
144 th weight: module.layers.3.blocks.0.norm1.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
145 th weight: module.layers.3.blocks.0.attn.relative_position_bias_table , shape =  torch.Size([169, 24]) , weight.dtype =  torch.float32
146 th weight: module.layers.3.blocks.0.attn.qkv.weight , shape =  torch.Size([2304, 768]) , weight.dtype =  torch.float32
147 th weight: module.layers.3.blocks.0.attn.qkv.bias , shape =  torch.Size([2304]) , weight.dtype =  torch.float32
148 th weight: module.layers.3.blocks.0.attn.proj.weight , shape =  torch.Size([768, 768]) , weight.dtype =  torch.float32
149 th weight: module.layers.3.blocks.0.attn.proj.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
150 th weight: module.layers.3.blocks.0.norm2.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
151 th weight: module.layers.3.blocks.0.norm2.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
152 th weight: module.layers.3.blocks.0.mlp.fc1.weight , shape =  torch.Size([3072, 768]) , weight.dtype =  torch.float32
153 th weight: module.layers.3.blocks.0.mlp.fc1.bias , shape =  torch.Size([3072]) , weight.dtype =  torch.float32
154 th weight: module.layers.3.blocks.0.mlp.fc2.weight , shape =  torch.Size([768, 3072]) , weight.dtype =  torch.float32
155 th weight: module.layers.3.blocks.0.mlp.fc2.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
156 th weight: module.layers.3.blocks.1.norm1.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
157 th weight: module.layers.3.blocks.1.norm1.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
158 th weight: module.layers.3.blocks.1.attn.relative_position_bias_table , shape =  torch.Size([169, 24]) , weight.dtype =  torch.float32
159 th weight: module.layers.3.blocks.1.attn.qkv.weight , shape =  torch.Size([2304, 768]) , weight.dtype =  torch.float32
160 th weight: module.layers.3.blocks.1.attn.qkv.bias , shape =  torch.Size([2304]) , weight.dtype =  torch.float32
161 th weight: module.layers.3.blocks.1.attn.proj.weight , shape =  torch.Size([768, 768]) , weight.dtype =  torch.float32
162 th weight: module.layers.3.blocks.1.attn.proj.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
163 th weight: module.layers.3.blocks.1.norm2.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
164 th weight: module.layers.3.blocks.1.norm2.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
165 th weight: module.layers.3.blocks.1.mlp.fc1.weight , shape =  torch.Size([3072, 768]) , weight.dtype =  torch.float32
166 th weight: module.layers.3.blocks.1.mlp.fc1.bias , shape =  torch.Size([3072]) , weight.dtype =  torch.float32
167 th weight: module.layers.3.blocks.1.mlp.fc2.weight , shape =  torch.Size([768, 3072]) , weight.dtype =  torch.float32
168 th weight: module.layers.3.blocks.1.mlp.fc2.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
169 th weight: module.norm.weight , shape =  torch.Size([768]) , weight.dtype =  torch.float32
170 th weight: module.norm.bias , shape =  torch.Size([768]) , weight.dtype =  torch.float32
171 th weight: module.head.weight , shape =  torch.Size([1000, 768]) , weight.dtype =  torch.float32
172 th weight: module.head.bias , shape =  torch.Size([1000]) , weight.dtype =  torch.float32
||||||||||| Model Stru |||||||||||

